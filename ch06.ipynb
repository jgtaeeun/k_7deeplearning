{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b646bdf4-3423-41f7-9328-6da9c148ca94",
   "metadata": {},
   "source": [
    "### 이미지 분류를 위한 신경망 - LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ece8cc29-90e6-4179-8a74-1783171cbe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f352dc57-b305-42ac-a9aa-461790300033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1\n",
    "image =torch.rand(batch_size,1,32,32)\n",
    "image.shape \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "188a9a72-58fe-49bb-8ee4-883d4b0aee64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 28, 28])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv=nn.Conv2d(1,6,5 ,  stride=1)\n",
    "\n",
    "x=conv(image)\n",
    "\n",
    "# ReLU 활성화 함수 추가\n",
    "relu = nn.ReLU()\n",
    "x = relu(x)  # [1, 6, 28, 28] (형상 유지)\n",
    "\n",
    "x.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b7cf71cb-de37-4f6a-8ec7-5ef374e62ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 14, 14])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool=nn.MaxPool2d(2, stride=2)\n",
    "x=pool(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71332b8b-332e-4a41-9e54-f13220c2c899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 10, 10])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2=nn.Conv2d(6,16,5 ,  stride=1)\n",
    "\n",
    "x=conv2(x)\n",
    "\n",
    "# ReLU 활성화 함수 추가\n",
    "relu = nn.ReLU()\n",
    "x = relu(x)  # [1, 6, 28, 28] (형상 유지)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f29d29aa-6102-4727-8412-af3e5ea50cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 5, 5])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2=nn.MaxPool2d(2, stride=2)\n",
    "x=pool2(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc7ef34b-9cb4-41b2-9cf3-49ba6d6097d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 120])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 평탄화\n",
    "x_flattened = x.view(x.size(0), -1)  # [1, 16*5*5]\n",
    "\n",
    "# 완전 연결층 정의\n",
    "linear = nn.Linear(16*5*5, 120)\n",
    "\n",
    "# 완전 연결층에 입력\n",
    "output = linear(x_flattened)\n",
    "\n",
    "# ReLU 활성화 함수 추가\n",
    "relu = nn.ReLU()\n",
    "output = relu(output)  # [1, 6, 28, 28] (형상 유지)\n",
    "\n",
    "print(output.shape)  # 출력 형상 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "beabab88-7da3-4d23-bc76-f1e9685d3b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 84])\n"
     ]
    }
   ],
   "source": [
    "# 완전 연결층 정의\n",
    "linear2 = nn.Linear(120, 84)\n",
    "\n",
    "# 완전 연결층에 입력\n",
    "output = linear2(output)\n",
    "\n",
    "# ReLU 활성화 함수 추가\n",
    "relu = nn.ReLU()\n",
    "output = relu(output)  # [1, 6, 28, 28] (형상 유지)\n",
    "\n",
    "print(output.shape)  # 출력 형상 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc3eae88-aae1-48f1-a586-038c49d16616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "tensor([[0.4646, 0.5354]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 세 번째 완전 연결층 정의\n",
    "linear3 = nn.Linear(84, 2)  # 입력 차원 84, 출력 차원 2\n",
    "\n",
    "# 세 번째 완전 연결층에 입력\n",
    "output = linear3(output)\n",
    "\n",
    "# 소프트맥스 활성화 함수 추가\n",
    "softmax = nn.Softmax(dim=1)\n",
    "output = softmax(output)  # [1, 2]\n",
    "\n",
    "print(output.shape)  # 출력 형상 확인\n",
    "print(output)  # 출력 값 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87ae12-d169-43c6-8abf-2542d66bb99b",
   "metadata": {},
   "source": [
    "### 모델의 네트워크 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab1806c4-65b8-4af0-bea7-4975edbb19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.cnn1=nn.Conv2d(in_channels=1, out_channels=6 , kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.cnn2=nn.Conv2d(in_channels=6, out_channels=16 , kernel_size=5, stride=1, padding=0)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "      \n",
    "\n",
    "# 자동으로 Linear 레이어의 입력 차원을 결정\n",
    "        self._to_linear = None\n",
    "        self.convs = nn.Sequential(\n",
    "        self.cnn1,\n",
    "        self.relu1,\n",
    "        self.maxpool1,\n",
    "        self.cnn2,\n",
    "        self.relu2,\n",
    "        self.maxpool2\n",
    "        )\n",
    "        \n",
    "        self._get_conv_output((1, 32, 32))  # MNIST 이미지 크기 (32x32)로 조정\n",
    "\n",
    "        self.fc1=nn.Linear(16*5*5, 120)\n",
    "        self.relu3=nn.ReLU()\n",
    "        self.fc2=nn.Linear(120, 84)\n",
    "        self.relu4=nn.ReLU()\n",
    "        self.fc3= nn.Linear(84, 2) \n",
    "        self.output=nn.Softmax(dim=1)\n",
    "\n",
    "    def _get_conv_output(self, shape):\n",
    "        with torch.no_grad():\n",
    "            n = torch.zeros(1, *shape)\n",
    "            n = self.convs(n)\n",
    "            self._to_linear = int(torch.prod(torch.tensor(n.shape[1:])))\n",
    "        return self._to_linear\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out=self.cnn1(x)\n",
    "        out=self.relu1(out)\n",
    "        out=self.maxpool1(out)\n",
    "        out=self.cnn2(out)\n",
    "        out=self.relu2(out)\n",
    "        out=self.maxpool2(out)\n",
    "        out=out.view(out.size(0), -1)\n",
    "        out=self.fc1(out)\n",
    "        out=self.fc2(out)\n",
    "        out=self.fc3(out)\n",
    "        out=self.output(out)\n",
    "        return out\n",
    "\n",
    " \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5e91d66b-af8c-4777-8e14-d8b530f56e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # MNIST 이미지를 32x32로 조정\n",
    "    transforms.Grayscale(),       # MNIST 데이터셋은 단일 채널 이미지를 사용하므로 이 변환을 적용\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6133eebc-f8a5-43da-9334-cd7a5d6d6114",
   "metadata": {},
   "source": [
    "### 모델객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb7f0564-a8c3-430d-85f4-eb9bc81b430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (cnn1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (convs): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
      "  (output): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=LeNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c042503c-4d5c-4037-8e8c-a1a690ffc7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=torch.rand(64,1,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03309100-04ff-483a-9b49-ef3b0c1aa552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4458, 0.5542],\n",
       "        [0.4472, 0.5528],\n",
       "        [0.4456, 0.5544],\n",
       "        [0.4471, 0.5529],\n",
       "        [0.4481, 0.5519],\n",
       "        [0.4465, 0.5535],\n",
       "        [0.4456, 0.5544],\n",
       "        [0.4451, 0.5549],\n",
       "        [0.4481, 0.5519],\n",
       "        [0.4489, 0.5511],\n",
       "        [0.4452, 0.5548],\n",
       "        [0.4473, 0.5527],\n",
       "        [0.4503, 0.5497],\n",
       "        [0.4451, 0.5549],\n",
       "        [0.4449, 0.5551],\n",
       "        [0.4488, 0.5512],\n",
       "        [0.4496, 0.5504],\n",
       "        [0.4445, 0.5555],\n",
       "        [0.4458, 0.5542],\n",
       "        [0.4472, 0.5528],\n",
       "        [0.4488, 0.5512],\n",
       "        [0.4451, 0.5549],\n",
       "        [0.4477, 0.5523],\n",
       "        [0.4464, 0.5536],\n",
       "        [0.4453, 0.5547],\n",
       "        [0.4448, 0.5552],\n",
       "        [0.4479, 0.5521],\n",
       "        [0.4460, 0.5540],\n",
       "        [0.4489, 0.5511],\n",
       "        [0.4484, 0.5516],\n",
       "        [0.4440, 0.5560],\n",
       "        [0.4460, 0.5540],\n",
       "        [0.4475, 0.5525],\n",
       "        [0.4450, 0.5550],\n",
       "        [0.4474, 0.5526],\n",
       "        [0.4451, 0.5549],\n",
       "        [0.4467, 0.5533],\n",
       "        [0.4465, 0.5535],\n",
       "        [0.4454, 0.5546],\n",
       "        [0.4463, 0.5537],\n",
       "        [0.4458, 0.5542],\n",
       "        [0.4456, 0.5544],\n",
       "        [0.4465, 0.5535],\n",
       "        [0.4450, 0.5550],\n",
       "        [0.4470, 0.5530],\n",
       "        [0.4440, 0.5560],\n",
       "        [0.4475, 0.5525],\n",
       "        [0.4446, 0.5554],\n",
       "        [0.4464, 0.5536],\n",
       "        [0.4449, 0.5551],\n",
       "        [0.4469, 0.5531],\n",
       "        [0.4493, 0.5507],\n",
       "        [0.4450, 0.5550],\n",
       "        [0.4459, 0.5541],\n",
       "        [0.4474, 0.5526],\n",
       "        [0.4464, 0.5536],\n",
       "        [0.4475, 0.5525],\n",
       "        [0.4458, 0.5542],\n",
       "        [0.4487, 0.5513],\n",
       "        [0.4496, 0.5504],\n",
       "        [0.4464, 0.5536],\n",
       "        [0.4462, 0.5538],\n",
       "        [0.4447, 0.5553],\n",
       "        [0.4483, 0.5517]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e8e9519-efbd-4339-92f7-d2b2698aae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer= optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3ee104-26a6-419e-b4b3-4dfa69c02d81",
   "metadata": {},
   "source": [
    "### datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "41d3fdf9-1ea7-405f-a124-bf877977a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets ,transforms\n",
    "import torchvision.transforms.v2 as v2\n",
    "dataset=datasets.MNIST('data', download=False, transform=v2.ToTensor()\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "efe23748-6e80-4f23-82d3-6cc812c5dc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([60000, 28, 28]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset.data), dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "506fc513-0228-47fd-8c4f-df58218dc4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Size([60000]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset.targets), dataset.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d9aaaa1-c12f-4704-b0bc-b2c3c7c3eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8990ae25-68a7-4a30-ada1-6f933dfadc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "015f6178-c63d-46eb-b595-5ba2a0660ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for X_train , y_label in data_loader:\n",
    "    print(X_train.shape, y_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2370ba6-a794-433b-9302-d90090df514f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27d11c51-c46a-404c-a099-6a6210b7831f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x256 and 400x120)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_train, y_label \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m      5\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, y_label)\n\u001b[0;32m      8\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[67], line 48\u001b[0m, in \u001b[0;36mLeNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool2(out)\n\u001b[0;32m     47\u001b[0m out\u001b[38;5;241m=\u001b[39mout\u001b[38;5;241m.\u001b[39mview(out\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(out)\n\u001b[0;32m     50\u001b[0m out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(out)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-book\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x256 and 400x120)"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for _ in range(epochs):\n",
    "    for X_train, y_label in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = loss_fn(outputs, y_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7e75d-4d4b-4d03-8ed6-fe6db0c791d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

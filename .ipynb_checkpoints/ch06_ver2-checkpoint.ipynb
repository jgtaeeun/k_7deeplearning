{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c235a38-2a74-4193-8e1d-c8ec7ef82221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "553db1c5-eb90-41e4-9028-c923abd1f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.cnn2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        \n",
    "         # Fully connected layer, adjust based on the output size of convolutional layers\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # Input size: 16 * 4 * 4\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)  # Output size: 10 (adjust based on the number of classes)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        out = out.view(out.size(0), -1)  # Flatten the tensor\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.fc3(out)\n",
    "        # Remove softmax if using CrossEntropyLoss, otherwise uncomment the following line\n",
    "        # out = nn.Softmax(dim=1)(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fce2a962-116f-4bd6-93d1-3fd8aabb9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f28f1d46-3476-4711-b623-e415ea8a7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9bf51497-bbca-430e-85f8-a0c0778e6d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets ,transforms\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torch.utils.data import DataLoader\n",
    "dataset=datasets.MNIST('data', download=False, transform=v2.ToTensor()\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39af994d-68af-40f9-bd66-aacabf52bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.v2 as v2\n",
    "\n",
    "transform = v2.Compose([\n",
    "    #v2.RandomCrop(224),\n",
    "    v2.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f39b137-2dca-42eb-b6ea-a82e8757ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10795531-3f64-4269-bb1f-931d121750aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for X_train , y_label in data_loader:\n",
    "    print(X_train.shape, y_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb8bcf10-570f-4fcf-974a-c13e09732832",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "for _ in range(epochs):\n",
    "    for X_train, y_label in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = loss_fn(outputs, y_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e8efc2c-627c-42e9-9c3a-e022db6128b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1 loss: 0.00018769491463899613\n",
      "  batch 101 loss: 0.08923924119677394\n",
      "  batch 201 loss: 0.07554846014594659\n",
      "  batch 301 loss: 0.09437668442260475\n",
      "  batch 401 loss: 0.0843579112389125\n",
      "  batch 501 loss: 0.07387211038265377\n",
      "  batch 601 loss: 0.06611148370895535\n",
      "  batch 701 loss: 0.061077661936869844\n",
      "  batch 801 loss: 0.05765245746471919\n",
      "  batch 901 loss: 0.0789700926025398\n",
      "  batch 1001 loss: 0.06134135769680142\n",
      "  batch 1101 loss: 0.06343622399726882\n",
      "  batch 1201 loss: 0.06151699303649366\n",
      "  batch 1301 loss: 0.07425575262866914\n",
      "  batch 1401 loss: 0.07132918133516795\n",
      "  batch 1501 loss: 0.08170683359727264\n",
      "  batch 1601 loss: 0.06336808898253367\n",
      "  batch 1701 loss: 0.07133196612587199\n",
      "  batch 1801 loss: 0.05066291296039708\n"
     ]
    }
   ],
   "source": [
    "EPOCHS  = 1\n",
    "for n in range(EPOCHS ):\n",
    "    print('EPOCH {}:'.format(n + 1))\n",
    "    epoch_loss = 0\n",
    "    step_loss = 0\n",
    "    for idx, (X_train, y_label) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = loss_fn(outputs, y_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step_loss += loss.item()\n",
    "        if idx % 100 == 0:\n",
    "            epoch_loss = step_loss / 100 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(idx + 1, epoch_loss))\n",
    "            step_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b9b14-bde4-47d3-aef4-7fb82c39cc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
